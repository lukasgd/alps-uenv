{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#cscs-user-environments","title":"CSCS User Environments","text":"<p>Documentation for the user-environments provided on CSCS Alps infrastructure.</p>"},{"location":"uenv-cp2k/","title":"CP2K","text":"<p>CP2K version <code>2023.2</code>.</p> <p>An environment that provides the latest version of CP2K, along with the libraries and tools required to build a different or custom version of CP2K.</p> <p>The following environment views are provided:</p> <ul> <li><code>cp2k-scalapack</code>: CP2K, dependencies, and ScaLAPACK as diagonalization library</li> <li><code>cp2k-scalapack-dev</code>: dependencies and ScaLAPACK</li> <li><code>cp2k-elpa</code>: CP2K, dependencies, and ELPA as diagonalization library</li> <li><code>cp2k-elpa-dev</code>: dependencies and ELPA</li> </ul>"},{"location":"uenv-cp2k/#building-a-custom-version-of-cp2k","title":"Building a custom version of CP2K","text":""},{"location":"uenv-cp2k/#using-modules","title":"Using modules","text":"<p>To build your version of CP2K do the following steps:</p> <pre><code># Load the required modules\nmodule load [...]\ncd cp2k\nmkdir build &amp;&amp; cd build\ncmake .. -DCMAKE_BUILD_TYPE=Release -DCP2K_SCALAPACK_VENDOR=MKL -DCP2K_USE_ACCEL=cuda -DCP2K_WITH_GPU=A100\nmake -j20\n</code></pre> <p>See CP2K's README_cmake.md for details.</p>"},{"location":"uenv-cp2k/#using-spack","title":"Using Spack","text":"<pre><code>uenv start cp2k-a100.squashfs\nexport SPACK_SYSTEM_CONFIG_PATH=/user-environment/config/\nspack install cp2k [...]\n</code></pre> <p>See Spack's CP2K package for details.</p>"},{"location":"uenv-gromacs/","title":"GROMACS","text":"<p>supports a100.</p>"},{"location":"uenv-linaro-forge/","title":"Linaro Forge (DDT) debugger","text":"<ul> <li>https://www.linaroforge.com/downloadForge</li> </ul> <p>Linaro Forge (formerly known as DDT) allows source-level debugging of Fortran, C, C++ and Python codes. It can be used for debugging serial, multi-threaded (OpenMP), multi-process (MPI) and accelerated (Cuda, OpenACC) programs running on research and production systems, including CSCS Alps system. It can be executed either as a graphical user interface or from the command-line.</p>"},{"location":"uenv-linaro-forge/#using-the-debugger","title":"Using the debugger","text":"<p>In order to debug your code on Alps, you need to:</p> <ul> <li>install the Forge/DDT client on your laptop,</li> <li>setup the user environment on Alps,</li> <li>build an executable with debug flags on Alps,</li> <li>launch a job with the debugger on Alps.</li> </ul>"},{"location":"uenv-linaro-forge/#install-the-client-on-your-laptop","title":"Install the client on your laptop","text":"<p>We recommend to download and install the desktop client on your local workstation/laptop. It will connect with the debug jobs running on Alps, offering a better user experience compared to opening ddt with X11 forwarding. The client can be downloaded for a selection of operating systems.</p> <p>Once installed, the client needs to be configured to connect to your preferred vcluster. For this, launch the client:</p> <ul> <li>mac: open /Applications/Linaro\\ Forge\\ Client\\ 23.0.1.app/</li> <li>linux: $HOME/linaro/forge/23.0.1/bin/ddt</li> </ul> <p>and setup the connection:</p> <pre><code>- open the 'Remote Launch' menu and click on 'configure' then 'Add' and set the fields, for example:\n    - Connection Name: alps\n\n    - Host Name: your-cscs-username-here@ela.cscs.ch your-cscs-username-here@clariden.cscs.ch\n    # Note that the clariden vlcuster name can be replaced with another vcluster name\n\n    - Remote install dir: uenv run IMG -- DDTDIR\n      # here we tell the client to use the ddt installed in the uenv image\n</code></pre> <p>where you can replace <code>IMG</code> and <code>DDTDIR</code> with for example:</p> <ul> <li><code>IMG</code>: full path to the uenv file and mount point, for example:</li> <li>/scratch/e1000/your-cscs-username-here/linaro-forge-23.0.3.squashfs:/user-tools</li> <li><code>DDTDIR</code>: full path to the tool, for example:</li> <li>/user-tools/linux-sles15-zen2/gcc-11.3.0/linaro-forge-23.0.3-3z4k6ijkcxcgqymv6mapv6xaela7m2q5/</li> </ul> <p>and</p> <pre><code>    - Remote Script:\n\n    - Private Key: _path-to-your-home_/.ssh/cscs-key\n\n    - Proxy through login node: yes (check the box)\n</code></pre> <p>Click <code>Test Remote Launch</code>. If the client can connect, you are ready to debug: click on <code>ok</code> and <code>close</code> (to save the configuration). You can now connect by going to <code>Remote Launch</code> and choose the <code>Alps</code> entry. If the client fails to connect, look at the message, check your ssh configuration and make sure you can ssh without the client.</p>"},{"location":"uenv-linaro-forge/#setup-the-environment","title":"Setup the environment","text":"<p><code>linaro-forge-23.0.3.squashfs</code> provides the latest version of Linaro Forge (23.0.3).</p> <ul> <li>On Alps: <pre><code>uenv start ./linaro-forge-23.0.3.squashfs\nuenv modules use\nmodule load linaro-forge\nddt --version\n# Version: 23.0.3\n</code></pre></li> </ul>"},{"location":"uenv-linaro-forge/#build-with-debug-flags","title":"Build with debug flags","text":"<p>Once the uenv is loaded and activated, the program to debug must be compiled with the <code>-g</code> (for cpu) and <code>-G</code> (for gpu) debugging flags. For example, let's build a cuda code with  a user environment:</p> <ul> <li>on Alps: <pre><code>uenv start store.squashfs\nuenv modules use\nmodule load gcc cray-mpich cuda\ngit clone -b ddt https://github.com/jgphpc/octree-miniapp \\\noctree-miniapp.git\nmake -C octree-miniapp.git/\n</code></pre></li> </ul>"},{"location":"uenv-linaro-forge/#launch-the-code-with-the-debugger","title":"Launch the code with the debugger","text":"<p>Given the unusual way of loading the uenv, the DDT client must be launched in <code>Manual Launch</code> mode (assuming that it is connected to Alps via <code>Remote Launch</code>):</p> <ul> <li>on the client: <pre><code>- open the 'Manual Launch' menu and\n- set the fields, for example:\n    - Number of processes: 12\n    - CUDA: yes (check the box for gpu exeutables)\n</code></pre> Listen and wait </li> </ul> <p>You can then launch ddt with the srun command (or a Slurm jobscript):</p> <ul> <li>on Alps: <pre><code>unset CUDA_VISIBLE_DEVICES\nsrun --uenv=$UENV_SQFS,TOOL_SQFS \\\n-l -N3 -n12 -t10 -pnvgpu \\\n./octree-miniapp.git/cuda_visible_devices.sh \\\n$DDT_CLIENT\n./octree-miniapp.git/neighbor_search.exe 120000\n</code></pre></li> </ul> <p>where for example:</p> <ul> <li>UENV_SQFS=$PWD/store.squashfs:/user-environment</li> <li>TOOL_SQFS=$PWD/linaro-forge-23.0.3.squashfs:/user-tools</li> <li>DDT_CLIENT=/user-tools/linux-sles15-zen2/gcc-11.3.0/linaro-forge-23.0.3-3z4k6ijkcxcgqymv6mapv6xaela7m2q5/bin/ddt-client</li> </ul> <p>This screenshot shows a debugging session on 12 gpus:</p> <p></p>"},{"location":"uenv-qe/","title":"Quantum ESPRESSO","text":"<p>https://www.quantum-espresso.org/</p> <p>An environment that provides the latest version of Quantum ESPRESSO, along with the libraries and tools required to build a different or custom version of Quantum ESPRESSO. At the moment a GPU-build environment is provided without a ScaLAPACK.</p> <p>The following environment views are provided:</p> <ul> <li>default : QuantumESPRESSO/7.1 itself + dependencies</li> <li>develop : only dependencies</li> </ul> <p>The following modules are provided:</p> <ul> <li>cmake/3.26.3</li> <li>cray-mpich/8.1.25-nvhpc</li> <li>cuda/11.8.0</li> <li>fftw/3.3.10</li> <li>gcc/11.3.0</li> <li>libxc/5.2.3</li> <li>nvhpc/22.11</li> <li>openblas/0.3.23</li> <li>patchelf/0.17.2</li> <li>quantum-espresso/7.1</li> </ul>"},{"location":"uenv-qe/#building-a-custom-version","title":"Building a custom version","text":""},{"location":"uenv-qe/#using-modules","title":"using modules","text":"<p>To build your version of QE do the following steps:</p> <pre><code>module load cmake cray-mpich/8.1.25-nvhpc cuda fftw libxc/5.2.3-nvhpc nvhpc openblas\ncd qe-71-dev\nmkdir build &amp;&amp; cd build\ncmake .. -DQE_ENABLE_OPENMP=1 -DQE_ENABLE_SCALAPACK=0 -DQE_ENABLE_LIBXC=1 -DQE_ENABLE_CUDA=1\nmake -j20\n</code></pre>"},{"location":"uenv-qe/#using-spack","title":"using Spack","text":"<p>todo.</p>"}]}